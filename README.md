# Apache-Spark-Distributed-Data-Processing-Fundamentals
The project focuses on **using PySpark for distributed data processing and analysis**, with an emphasis on understanding Spark’s programming model rather than performance tuning or production deployment.  The work is educational in nature and aims to build familiarity with Spark’s core abstractions through hands-on exercises.
